{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pretrained_Assignment_1_IR_Search_News.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KijB6g_6X8W"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jpkh_5j6cC6"
      },
      "source": [
        "Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRpprXUU6e4x",
        "outputId": "740a89b2-51c0-4654-ee81-45eb5a1390d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import math\n",
        "import operator\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "import json\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "np.random.seed(2018)\n",
        "nltk.download('wordnet')\n",
        "import random"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PebYnIo49DWJ"
      },
      "source": [
        "# Preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAktczRy9qQT"
      },
      "source": [
        "Stemming and tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x_KH3xk9tMF"
      },
      "source": [
        "'''\n",
        "Preprocessing function - Porter stemmer\n",
        "'''\n",
        "def preprocess_docs(data):\n",
        "    processed_data=[]\n",
        "    stemmer = PorterStemmer()\n",
        "    for d in data:\n",
        "        tempf=[]\n",
        "        temp = d\n",
        "        temp = ''.join(c for c in temp if c not in string.punctuation)\n",
        "        temp = nltk.word_tokenize(temp)\n",
        "        temp = [w.lower() for w in temp]\n",
        "        temp = [t for t in temp if t not in nltk.corpus.stopwords.words('english')]\n",
        "        for word in temp:\n",
        "          tempf.append(stemmer.stem(word))\n",
        "        processed_data.append(tempf)\n",
        "    return processed_data"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs05bygEPoKH"
      },
      "source": [
        "Save my files and load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRmzMs0ePrFX"
      },
      "source": [
        "import pickle\n",
        "\n",
        "#save objects\n",
        "def store_data():\n",
        "\n",
        "  pickle_out = open(\"/content/drive/My Drive/IR Assignment/saved objects/comb_news.pickle\",\"wb\")\n",
        "  pickle.dump(comb_news, pickle_out)\n",
        "  pickle_out.close()\n",
        "\n",
        "  pickle_out = open(\"/content/drive/My Drive/IR Assignment/saved objects/review.pickle\",\"wb\")\n",
        "  pickle.dump(review, pickle_out)\n",
        "  pickle_out.close()\n",
        "\n",
        "  pickle_out = open(\"/content/drive/My Drive/IR Assignment/saved objects/master_dict.pickle\",\"wb\")\n",
        "  pickle.dump(master_dict, pickle_out)\n",
        "  pickle_out.close()\n",
        "\n",
        "  pickle_out = open(\"/content/drive/My Drive/IR Assignment/saved objects/total_reviews.pickle\",\"wb\")\n",
        "  pickle.dump(total_reviews, pickle_out)\n",
        "  pickle_out.close()\n",
        "\n",
        "  pickle_out = open(\"/content/drive/My Drive/IR Assignment/saved objects/dictionary.pickle\",\"wb\")\n",
        "  pickle.dump(dictionary, pickle_out)\n",
        "  pickle_out.close()\n",
        "\n",
        "  pickle_out = open(\"/content/drive/My Drive/IR Assignment/saved objects/lda_model.pickle\",\"wb\")\n",
        "  pickle.dump(lda_model, pickle_out)\n",
        "  pickle_out.close()\n",
        "\n",
        "  pickle_out = open(\"/content/drive/My Drive/IR Assignment/saved objects/doc_lda.pickle\",\"wb\")\n",
        "  pickle.dump(doc_lda, pickle_out)\n",
        "  pickle_out.close()\n",
        "\n",
        "  pickle_out = open(\"/content/drive/My Drive/IR Assignment/saved objects/links.pickle\",\"wb\")\n",
        "  pickle.dump(links, pickle_out)\n",
        "  pickle_out.close()\n",
        "\n",
        "#store_data()\n",
        "\n",
        "#initialising objects\n",
        "# temp_comb_news = []\n",
        "# temp_review = []\n",
        "# temp_master_dict = {}\n",
        "# temp_total_reviews = 1\n",
        "# temp_dictionary = {}\n",
        "# temp_lda_model\n",
        "# temp_doc_lda = {}\n",
        "\n",
        "#load objects\n",
        "def load_data():\n",
        "\n",
        "  pickle_in = open(\"/content/drive/My Drive/IR Assignment/saved objects/comb_news.pickle\",\"rb\")\n",
        "  temp_comb_news = pickle.load(pickle_in)\n",
        "  pickle_in.close()\n",
        "\n",
        "  pickle_in = open(\"/content/drive/My Drive/IR Assignment/saved objects/review.pickle\",\"rb\")\n",
        "  temp_review = pickle.load(pickle_in)\n",
        "  pickle_in.close()\n",
        "\n",
        "  pickle_in = open(\"/content/drive/My Drive/IR Assignment/saved objects/master_dict.pickle\",\"rb\")\n",
        "  temp_master_dict = pickle.load(pickle_in)\n",
        "  pickle_in.close()\n",
        "\n",
        "  pickle_in = open(\"/content/drive/My Drive/IR Assignment/saved objects/total_reviews.pickle\",\"rb\")\n",
        "  temp_total_reviews = pickle.load(pickle_in)\n",
        "  pickle_in.close()\n",
        "\n",
        "  pickle_in = open(\"/content/drive/My Drive/IR Assignment/saved objects/dictionary.pickle\",\"rb\")\n",
        "  temp_dictionary = pickle.load(pickle_in)\n",
        "  pickle_in.close()\n",
        "\n",
        "  pickle_in = open(\"/content/drive/My Drive/IR Assignment/saved objects/lda_model.pickle\",\"rb\")\n",
        "  temp_lda_model = pickle.load(pickle_in)\n",
        "  pickle_in.close()\n",
        "\n",
        "  pickle_in = open(\"/content/drive/My Drive/IR Assignment/saved objects/doc_lda.pickle\",\"rb\")\n",
        "  temp_doc_lda = pickle.load(pickle_in)\n",
        "  pickle_in.close()\n",
        "\n",
        "  pickle_in = open(\"/content/drive/My Drive/IR Assignment/saved objects/links.pickle\",\"rb\")\n",
        "  temp_links = pickle.load(pickle_in)\n",
        "  pickle_in.close()\n",
        "\n",
        "  return temp_comb_news,temp_review,temp_master_dict,temp_total_reviews,temp_dictionary,temp_lda_model,temp_doc_lda,temp_links\n",
        "\n",
        "comb_news,review,master_dict,total_reviews,dictionary,lda_model,doc_lda,links = load_data()\n",
        "\n",
        "# comb_news = temp_comb_news\n",
        "# review = temp_review\n",
        "# master_dict = temp_master_dict\n",
        "# total_reviews = temp_total_reviews\n",
        "# dictionary = temp_dictionary\n",
        "# lda_model = temp_lda_model\n",
        "# doc_lda = temp_doc_lda\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdVbDflIWEiO",
        "outputId": "9a471138-3402-45e0-ab23-78e6013a0a2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#dummy cell\n",
        "print(1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwCWpyMACAEW"
      },
      "source": [
        "# Extracting results from query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kePj6Qy-CLmh"
      },
      "source": [
        "Function to get results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LjEgHwwCRQT"
      },
      "source": [
        "def getResults(myquery):\n",
        "\n",
        "  sample_query = [myquery]\n",
        "\n",
        "  #preprocessing query before evaulation\n",
        "  sample_query = preprocess_docs(sample_query)\n",
        "  query = sample_query[0]\n",
        "  print(query)\n",
        "\n",
        "  query_dict = {}\n",
        "\n",
        "  for query_term in query:\n",
        "\n",
        "  # query term should be present in my master dictionary\n",
        "    if query_term in master_dict:\n",
        "\n",
        "      if query_term in query_dict:\n",
        "        query_dict[query_term]['tf'] += 1\n",
        "        query_dict[query_term]['df'] = len(master_dict[query_term])\n",
        "        query_dict[query_term]['tf-idf'] = (1+math.log10(query_dict[query_term]['tf']))*(math.log10(total_reviews/query_dict[query_term]['df']))\n",
        "      else:\n",
        "        query_dict.update({query_term:{'tf':1, 'df':0, 'tf-idf':0.1}})\n",
        "        query_dict[query_term]['df'] = len(master_dict[query_term])\n",
        "        query_dict[query_term]['tf-idf'] = (1+math.log10(query_dict[query_term]['tf']))*(math.log10(total_reviews/query_dict[query_term]['df']))\n",
        "\n",
        "\n",
        "  #normalise tf-idf for query\n",
        "  q_norm_factor = 0;\n",
        "\n",
        "  for term in query_dict:\n",
        "    q_norm_factor += query_dict[term]['tf-idf']*query_dict[term]['tf-idf']\n",
        "\n",
        "  q_norm_factor = math.sqrt(q_norm_factor)\n",
        "\n",
        "  for term in query_dict:\n",
        "    query_dict[term]['tf-idf'] = query_dict[term]['tf-idf']/q_norm_factor\n",
        "\n",
        "  #topic modelling of query\n",
        "  bow_vector = dictionary.doc2bow(query)\n",
        "  query_lda = {}\n",
        "\n",
        "  for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    query_lda.update({index:score})\n",
        "  \n",
        "  #calculating cosine similarity\n",
        "\n",
        "\n",
        "  result = {} #to store all the documents as result and their cosine similarity score\n",
        "\n",
        "  for query_term in query_dict:\n",
        "\n",
        "    for doc_num in master_dict[query_term]:\n",
        "\n",
        "      if doc_num in result:\n",
        "        result[doc_num] += query_dict[query_term]['tf-idf']*master_dict[query_term][doc_num]['tf-idf']\n",
        "      else:\n",
        "        result.update({doc_num: 0.1})\n",
        "        result[doc_num] = query_dict[query_term]['tf-idf']*master_dict[query_term][doc_num]['tf-idf']\n",
        "\n",
        "  #calculating LDA score for each doc in results\n",
        "  result_LDA = {}\n",
        "\n",
        "  for doc_num in result:\n",
        "    result_LDA.update({doc_num:0})\n",
        "\n",
        "    for topic_id in query_lda:\n",
        "\n",
        "      if topic_id in doc_lda[doc_num]:\n",
        "        #dot product of lda scores\n",
        "        result_LDA[doc_num] += query_lda[topic_id]*doc_lda[doc_num][topic_id]\n",
        "\n",
        "  #extracting results with LDA\n",
        "  for doc_num in result:\n",
        "    result[doc_num] += result_LDA[doc_num]/3\n",
        "\n",
        "  sorted_result_lda = sorted(result.items(), key=operator.itemgetter(1),reverse=True)\n",
        "  \n",
        "  for ind in range(10):\n",
        "    print(comb_news[sorted_result_lda[ind][0]])\n",
        "\n",
        "  result_s = []\n",
        "  for ind in range(10):\n",
        "    cont = []\n",
        "    cont.append(comb_news[sorted_result_lda[ind][0]])\n",
        "    cont.append(links[sorted_result_lda[ind][0]])\n",
        "    result_s.append(cont)\n",
        "  \n",
        "  return result_s"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlCfXJ6lDTYp"
      },
      "source": [
        "# Flask Application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uVvDF07DYcR",
        "outputId": "ba11c5c3-366a-47ba-b115-1c405a48c485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.6/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSPKnfImDbc3",
        "outputId": "15b729b0-9404-4e6f-de22-f095589ed623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import render_template,request\n",
        "from flask import Flask\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "\n",
        "@app.route(\"/\")\n",
        "def give_query():\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "@app.route('/results',methods=[\"POST\"])\n",
        "def get_result():\n",
        "\tquery = request.form.get('query')\n",
        "\tif not query:\n",
        "\t\treturn \"Query not entered\"\n",
        "\tresult_s = getResults(query)\n",
        "\t# for ind in range(10):\n",
        "\t# \tresult_s.append(comb_news[sorted_result_lda[ind][0]])\n",
        "\n",
        "\treturn render_template(\"result.html\",q=query,res=result_s)\n",
        "  \n",
        "def home():\n",
        "    return \"<h1>Running Flask on Google Colab!</h1>\"\n",
        "\n",
        "app.run()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://ce4f54d7ca7c.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Oct/2020 10:05:07] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Oct/2020 10:05:44] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Oct/2020 10:05:45] \"\u001b[37mGET /static/master.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Oct/2020 10:05:45] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['trump', 'kim']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Oct/2020 10:08:30] \"\u001b[37mPOST /results HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Leave It To Kim Kardashian To Dress Up Like Kim Kardashian For Halloween. She would.\n",
            "We Have A Lot Of Questions About Kim Kardashian's Latest Outfit. EXPLAIN YOURSELF, KIM.\n",
            "All Of Kim Kardashian's Major Magazine Covers (PHOTOS). Stefano Tonchi, editor-in-chief of W magazine put Kim on the cover for his November 2010 issue. When asked why he chose Kim\n",
            "Kim Kardashian Cleavage Also Shows Off Bra (PHOTOS). See Kim's style through the years... Oh well. At least she's wearing one. In other Kim Kardashian News, we are pleased to\n",
            "Kim Kardashian Knows How To Dress Her Curves (PHOTO). Click here to see Kim Kardashian's style evolution. WHO: TV personality, entrepreneur and Kanye's better half, Kim Kardashian\n",
            "'Kim Possible' Live-Action Movie Finds Its New Kim And Ron. Call them, beep them if you wanna reach them.\n",
            "Donald Trump Will Meet With Kim Jong Un By May, South Korea Says. Kim reportedly has expressed his \"eagerness to meet\" with Trump as soon as possible.\n",
            "Kim Kardashian's Surprising Outfit: She's Wearing Colors Again! (PHOTOS). Until Monday, when Kim left Miami, where's she's been filming a third season of \"Kourtney and Kim Take Miami,\" for a flight\n",
            "Snooki Gives Kim Kardashian Advice For Giving Birth In Style (VIDEO). See how Kim's gone glam since getting pregnant: Oh, how well she knows Kim. Think we're making any of this up? Believe it\n",
            "Kim Kardashian To Fashion Week? Star Arrives In Paris In Bizarre Outfit (PHOTOS). PHOTOS: Kim Kardashian's strange monochromatic style strikes again! Even though Kim has an affinity for the city of romance\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Oct/2020 10:08:30] \"\u001b[37mGET /static/styles.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Oct/2020 10:09:45] \"\u001b[37mPOST /results HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['trump', 'kim']\n",
            "Leave It To Kim Kardashian To Dress Up Like Kim Kardashian For Halloween. She would.\n",
            "We Have A Lot Of Questions About Kim Kardashian's Latest Outfit. EXPLAIN YOURSELF, KIM.\n",
            "All Of Kim Kardashian's Major Magazine Covers (PHOTOS). Stefano Tonchi, editor-in-chief of W magazine put Kim on the cover for his November 2010 issue. When asked why he chose Kim\n",
            "Kim Kardashian Cleavage Also Shows Off Bra (PHOTOS). See Kim's style through the years... Oh well. At least she's wearing one. In other Kim Kardashian News, we are pleased to\n",
            "Kim Kardashian Knows How To Dress Her Curves (PHOTO). Click here to see Kim Kardashian's style evolution. WHO: TV personality, entrepreneur and Kanye's better half, Kim Kardashian\n",
            "'Kim Possible' Live-Action Movie Finds Its New Kim And Ron. Call them, beep them if you wanna reach them.\n",
            "Donald Trump Will Meet With Kim Jong Un By May, South Korea Says. Kim reportedly has expressed his \"eagerness to meet\" with Trump as soon as possible.\n",
            "Kim Kardashian's Surprising Outfit: She's Wearing Colors Again! (PHOTOS). Until Monday, when Kim left Miami, where's she's been filming a third season of \"Kourtney and Kim Take Miami,\" for a flight\n",
            "Snooki Gives Kim Kardashian Advice For Giving Birth In Style (VIDEO). See how Kim's gone glam since getting pregnant: Oh, how well she knows Kim. Think we're making any of this up? Believe it\n",
            "Kim Kardashian To Fashion Week? Star Arrives In Paris In Bizarre Outfit (PHOTOS). PHOTOS: Kim Kardashian's strange monochromatic style strikes again! Even though Kim has an affinity for the city of romance\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Oct/2020 10:10:18] \"\u001b[33mGET /robots.txt HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [25/Oct/2020 10:10:18] \"\u001b[33mGET /robots.txt HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [25/Oct/2020 10:10:18] \"\u001b[33mGET /ads.txt HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}